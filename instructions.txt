Start local llm in one terminal: 
ollama run phi3

(Optional) Start the API server
Only needed if you want to test the FastAPI endpoints.
uvicorn app.main:app --reload

Run retrieval-only embedding benchmarks
Without reranking:
python -m evaluation.run_embedding_benchmark
With reranking:
python -m evaluation.run_embedding_benchmark --reranker

Run end-to-end RAG evaluation (answer-level)
Without reranking:
python -m evaluation.run_rag_eval
With reranking:
python -m evaluation.run_rag_eval --reranker


