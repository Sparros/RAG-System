Neural networks are computational models inspired by the structure and function of biological neural systems, particularly the brain. They consist of interconnected units called artificial neurons that process information by responding to input signals and transmitting output signals to other neurons. Neural networks are widely used in machine learning for tasks such as pattern recognition, classification, regression, and prediction.

An artificial neuron receives one or more inputs, each associated with a weight. The weighted inputs are summed and passed through an activation function, which determines whether the neuron produces an output. Common activation functions include sigmoid, rectified linear unit (ReLU), and hyperbolic tangent. By adjusting weights during training, neural networks learn to approximate complex functions.

Neural networks are typically organized into layers. The input layer receives raw data, such as images or text features. One or more hidden layers perform intermediate computations, and the output layer produces the final result. Deep neural networks contain many hidden layers and are capable of learning hierarchical representations of data.

Training a neural network involves providing examples with known outputs and minimizing a loss function that measures the difference between predicted and actual results. This is usually done using gradient-based optimization methods such as stochastic gradient descent and backpropagation. Backpropagation computes gradients of the loss function with respect to each weight by applying the chain rule.

Neural networks can be categorized into several architectures. Feedforward networks pass information in one direction only. Convolutional neural networks are designed to process grid-like data such as images and use convolutional layers to detect local patterns. Recurrent neural networks are designed for sequential data and maintain internal state, making them useful for time-series and language tasks. Transformer architectures, which rely on attention mechanisms rather than recurrence, have become dominant in modern natural language processing.

Although inspired by biology, artificial neural networks are simplified mathematical models and do not replicate the full complexity of biological neurons. Nonetheless, they have proven effective across a wide range of scientific and industrial applications.